{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a containerized EC2 instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S3 upload options:\n",
    "- Boto3:\n",
    "    - http://stackabuse.com/example-upload-a-file-to-aws-s3/\n",
    "    - http://boto3.readthedocs.io/en/latest/guide/migration.html#installation-configuration\n",
    "    - https://gist.github.com/freewayz/1fbd00928058c3d682a0e25367cc8ea4\n",
    "- Amazon CLI: \n",
    "    - https://docs.aws.amazon.com/cli/latest/userguide/using-s3-commands.html\n",
    "    - https://aws.amazon.com/getting-started/tutorials/backup-to-s3-cli/\n",
    "    \n",
    "Both are available to Rackham,\n",
    "\n",
    "Boto3:\n",
    "```\n",
    "module load python && virtualenv venv && source venv/bin/activate && pip\n",
    "install boto3\n",
    "# Or by running \"pip install -y boto3 --user\"\n",
    "```\n",
    "\n",
    "CLI: awscli/1.11.140"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Console test\n",
    "\n",
    "https://aws.amazon.com/getting-started/tutorials/backup-to-s3-cli/\n",
    "\n",
    "```\n",
    "$ sudo apt install awscli\n",
    "$ aws configure\n",
    "AWS Access Key ID [None]: \n",
    "AWS Secret Access Key [None]:\n",
    "(also used eu-central-1 for region, and json as format)\n",
    "```\n",
    "\n",
    "The above commang needs SSL certificates. To generate the aws keys:\n",
    "\n",
    "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/set-up-ami-tools.html?icmpid=docs_iam_console#ami-tools-managing-certs\n",
    "\n",
    "```\n",
    "$ openssl genrsa 2048 > aws-private.pem\n",
    "$ openssl req -new -x509 -nodes -sha256 -days 365 -key aws-private.pem -outform PEM -out aws-certificate.pem\n",
    "\n",
    "if in dire need for security use:\n",
    "$ sudo apt-get install xclip\n",
    "$ xclip -sel clip < ~/.ssh/aws-private.pem\n",
    "```\n",
    "\n",
    "```\n",
    "aws s3 mb s3://my-first-backup-bucket\n",
    "upload:\n",
    "aws s3 cp “C:\\users\\my first backup.bak” s3://my-first-backup-bucket/\n",
    "download:\n",
    "aws s3 cp s3://my-first-backup-bucket/my-first-backup.bak ./\n",
    "delete:\n",
    "aws s3 rm s3://my-first-backup-bucket/my-first-backup.bak\n",
    "```\n",
    "\n",
    "anyway, on rackham tests work!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boto3 test\n",
    "\n",
    "- https://boto3.readthedocs.io/en/latest/guide/s3-example-creating-buckets.html\n",
    "- http://boto3.readthedocs.io/en/latest/reference/services/s3.html\n",
    "\n",
    "conda install -c anaconda boto3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Location': 'http://jo8a7fn8sfn8.s3.amazonaws.com/',\n",
       " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '0',\n",
       "   'date': 'Wed, 02 May 2018 14:29:21 GMT',\n",
       "   'location': 'http://jo8a7fn8sfn8.s3.amazonaws.com/',\n",
       "   'server': 'AmazonS3',\n",
       "   'x-amz-id-2': 'Jz2XiyGad4yBOiFyBvd4Z7uXvHqaP2+B+3wnFRotaRICsD25+9pDJ3Vc7cqGaJVzPPDQjeZtDFg=',\n",
       "   'x-amz-request-id': '588D5CD6FB259F3E'},\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HostId': 'Jz2XiyGad4yBOiFyBvd4Z7uXvHqaP2+B+3wnFRotaRICsD25+9pDJ3Vc7cqGaJVzPPDQjeZtDFg=',\n",
       "  'RequestId': '588D5CD6FB259F3E',\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "s3.create_bucket(Bucket='jo8a7fn8sfn8', CreateBucketConfiguration={'LocationConstraint': 'eu-central-1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket List: ['jo8a7fn8sfn8']\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Call S3 to list current buckets\n",
    "response = s3.list_buckets()\n",
    "\n",
    "# Get a list of all bucket names from the response\n",
    "buckets = [bucket['Name'] for bucket in response['Buckets']]\n",
    "\n",
    "# Print out the bucket list\n",
    "print(\"Bucket List: %s\" % buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "filename = '/media/sergiu/workpc/data/work/andersson/test/temp/crass.crispr'\n",
    "bucket_name = 'jo8a7fn8sfn8'\n",
    "\n",
    "# Uploads the given file using a managed uploader, which will split up large\n",
    "# files automatically and upload parts in parallel.\n",
    "s3.upload_file(filename, bucket_name, filename)\n",
    "\n",
    "# or\n",
    "s3.Object('mybucket', 'hello.txt').put(Body=open('/tmp/hello.txt', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://boto3.readthedocs.io/en/latest/guide/migrations3.html#deleting-a-bucket\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket('jo8a7fn8sfn8')\n",
    "\n",
    "exists = True\n",
    "try:\n",
    "    s3.meta.client.head_bucket(Bucket='jo8a7fn8sfn8')\n",
    "except botocore.exceptions.ClientError as e:\n",
    "    # If a client error is thrown, then check that it was a 404 error.\n",
    "    # If it was a 404 error, then the bucket does not exist.\n",
    "    error_code = int(e.response['Error']['Code'])\n",
    "    if error_code == 404:\n",
    "        exists = False\n",
    "\n",
    "if exists==True:\n",
    "    for key in bucket.objects.all():\n",
    "        key.delete()\n",
    "    bucket.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Docker CE on Ubuntu\n",
    "\n",
    "https://docs.docker.com/install/linux/docker-ce/ubuntu/\n",
    "\n",
    "```\n",
    "$ sudo apt-get update\n",
    "# allow apt to use https repos\n",
    "$ sudo apt-get install \\\n",
    "    apt-transport-https \\\n",
    "    ca-certificates \\\n",
    "    curl \\\n",
    "    software-properties-common\n",
    "# add the repo key\n",
    "$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\n",
    "\n",
    "$ sudo add-apt-repository \\\n",
    "   \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\\n",
    "   $(lsb_release -cs) \\\n",
    "   stable\"\n",
    "$ sudo apt-get update\n",
    "$ sudo apt-get install docker-ce\n",
    "```\n",
    "\n",
    "Now following this to link the image directories to my hdd:\n",
    "https://forums.docker.com/t/how-do-i-change-the-docker-image-installation-directory/1169\n",
    "\n",
    "```\n",
    "sudo nano /etc/default/docker\n",
    "DOCKER_OPTS=\"--dns 8.8.8.8 --dns 8.8.4.4 -g /media/sergiu/lappie/docker\"\n",
    "service docker restart\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
